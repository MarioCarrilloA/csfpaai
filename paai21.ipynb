{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAN--lUwyg-s"
   },
   "source": [
    "# PAAI21\n",
    "\n",
    "Image classification can be successfully solved by modern CNNs. However, there are still\n",
    "a plethora of questions regarding how those models manage to extract and model general\n",
    "features for large number of classes. A straightforward strategy is to focus on saliency i.e.,\n",
    "the area of the image that has a maximal response w.r.t. the predicted class. The aim of\n",
    "this project is to complement that idea by estimating the number of salient regions that\n",
    "common image classifiers react to and measure the consistency of those regions\n",
    "regarding the predicted class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMqc3_YRsmFQ"
   },
   "source": [
    "## Resnet18 - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T15:59:11.388029Z",
     "iopub.status.busy": "2021-05-28T15:59:11.387676Z",
     "iopub.status.idle": "2021-05-28T15:59:18.990836Z",
     "shell.execute_reply": "2021-05-28T15:59:18.989987Z",
     "shell.execute_reply.started": "2021-05-28T15:59:11.387955Z"
    },
    "id": "m_kAyJN2sxVU"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import skimage.transform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torch import topk\n",
    "from torchvision import models, datasets, transforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T15:59:47.187124Z",
     "iopub.status.busy": "2021-05-28T15:59:47.186797Z",
     "iopub.status.idle": "2021-05-28T15:59:47.249642Z",
     "shell.execute_reply": "2021-05-28T15:59:47.248605Z",
     "shell.execute_reply.started": "2021-05-28T15:59:47.187094Z"
    },
    "id": "-LNUnIXCyDwe",
    "outputId": "e03fd8b1-c293-4feb-c80f-5c281918ac62"
   },
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# Define paramters and other variables\n",
    "# -------------------------------------\n",
    "\n",
    "# Classes labels CIFAR-10\n",
    "classes = ('plane',\n",
    "           'auto',\n",
    "           'bird',\n",
    "           'cat',\n",
    "           'deer',\n",
    "           'dog',\n",
    "           'frog',\n",
    "           'horse',\n",
    "           'ship',\n",
    "           'truck')\n",
    "\n",
    "# CIFAR1-10 parameters\n",
    "input_size = 32\n",
    "num_classes = 10\n",
    "\n",
    "# Check for GPU/CPU to allocate tensor\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T15:59:52.720698Z",
     "iopub.status.busy": "2021-05-28T15:59:52.720364Z",
     "iopub.status.idle": "2021-05-28T16:00:01.910382Z",
     "shell.execute_reply": "2021-05-28T16:00:01.909584Z",
     "shell.execute_reply.started": "2021-05-28T15:59:52.720667Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    " #   normalize,\n",
    "])\n",
    "\n",
    "# Download & transform CIFAR-10 datasets\n",
    "train_full_dataset = datasets.CIFAR10(\"./data\", train=True,\n",
    "                                 transform=train_transform, download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\"./data\", train=False,\n",
    "                                transform=test_transform, download=True)\n",
    "\n",
    "# Split datasets\n",
    "train_num_samples = int(len(train_full_dataset) * 0.9) # 90%(Training set).\n",
    "val_num_samples = int(len(train_full_dataset) * 0.1)   #10%(Validation set)\n",
    "\n",
    "print(\"Division: \",train_num_samples, val_num_samples)\n",
    "train_dataset, validation_dataset = random_split(train_full_dataset, [train_num_samples, val_num_samples])\n",
    "print(\"Dataset lenght: \", len(train_dataset))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=5000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T16:00:19.890038Z",
     "iopub.status.busy": "2021-05-28T16:00:19.889724Z",
     "iopub.status.idle": "2021-05-28T16:00:19.896596Z",
     "shell.execute_reply": "2021-05-28T16:00:19.895271Z",
     "shell.execute_reply.started": "2021-05-28T16:00:19.890010Z"
    },
    "id": "9XktR_EJ_ERd"
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.resnet = models.resnet18(pretrained=False, num_classes=10)\n",
    "\n",
    "        self.resnet.conv1 = torch.nn.Conv2d(\n",
    "            3, 64, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.resnet.maxpool = torch.nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T16:00:24.910892Z",
     "iopub.status.busy": "2021-05-28T16:00:24.910574Z",
     "iopub.status.idle": "2021-05-28T16:00:24.928229Z",
     "shell.execute_reply": "2021-05-28T16:00:24.927247Z",
     "shell.execute_reply.started": "2021-05-28T16:00:24.910861Z"
    },
    "id": "01PMfDH2H5we"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, epoch, verbose=False):\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "  \n",
    "    for data, target in train_loader:\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(data)\n",
    "        loss = F.nll_loss(prediction, target)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss.append(loss.item())\n",
    "    \n",
    "        avg_loss = sum(total_loss) / len(total_loss)\n",
    "        if (verbose):\n",
    "            print(\"Training set: Epoch: {} Average Loss: {:.2f}\".format(epoch, avg_loss))\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def _get_classes_percentage(targets, predictions):\n",
    "    num_classes = len(classes)\n",
    "    num_samples = len(targets)\n",
    "\n",
    "    # Init class lists\n",
    "    correct_per_class = [0] * num_classes\n",
    "    total_per_class = [0] * num_classes\n",
    "    percentage_per_class = [0] * num_classes\n",
    "    for i in range(num_samples):\n",
    "        class_id = targets[i]\n",
    "        if targets[i] == predictions[i]:\n",
    "            correct_per_class[class_id] += 1\n",
    "        total_per_class[class_id] += 1\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        percentage_per_class[i] = 100 * (correct_per_class[i] / total_per_class[i])\n",
    "    \n",
    "    return percentage_per_class\n",
    "            \n",
    "\n",
    "def test_model(model, test_loader, verbose=False):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        with torch.no_grad():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            prediction = model(data)\n",
    "            loss += F.nll_loss(prediction, target, reduction=\"sum\")\n",
    "\n",
    "            prediction = prediction.max(1)[1]\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "            loss /= len(test_loader.dataset)\n",
    "            percentage_correct = 100.0 * correct / len(test_loader.dataset)\n",
    "            percentage_classes = _get_classes_percentage(target, prediction)\n",
    "\n",
    "            if (verbose):\n",
    "                print(\"Testing set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\".format(\n",
    "                    loss, correct, len(test_loader.dataset), percentage_correct))\n",
    "      \n",
    "    return loss, percentage_correct, percentage_classes\n",
    "\n",
    "\n",
    "def format_model_output(e, avg_loss, tloss, pct_correct, pct_classes):\n",
    "    output  = \"Epoch:{: <2} \".format(e)\n",
    "    output += \"TrainLoss:{: <4.2f} \".format(avg_loss)\n",
    "    output += \"TestLoss:{: <4.2f} \".format(tloss)\n",
    "    output += \"Accuracy:{: <5.2f}% \".format(pct_correct)\n",
    "\n",
    "    num_classes = len(classes)\n",
    "    for i in range(num_classes):\n",
    "        output += \"{}:{: <5.2f}% \".format(classes[i], pct_classes[i])\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T16:00:30.643996Z",
     "iopub.status.busy": "2021-05-28T16:00:30.643676Z",
     "iopub.status.idle": "2021-05-28T16:00:30.650626Z",
     "shell.execute_reply": "2021-05-28T16:00:30.649767Z",
     "shell.execute_reply.started": "2021-05-28T16:00:30.643968Z"
    },
    "id": "-FoYO8sgNWgm",
    "outputId": "2414f4b2-0396-4cb1-b1aa-bbbb675f6d90"
   },
   "outputs": [],
   "source": [
    "def build_model(train_loader, test_loader):\n",
    "    # Hyperparameters\n",
    "    epochs=50\n",
    "    lr=0.1\n",
    "    \n",
    "    model = Model()\n",
    "    model = model.cuda()\n",
    "\n",
    "    milestones = [25, 40]\n",
    "\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=milestones, gamma=0.1)\n",
    "\n",
    "    print(\"Start train/test resnet18!\")\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        avg_loss = train_model(model, train_loader, optimizer, epoch)\n",
    "        loss, pct_correct, pct_classes = test_model(model, test_loader)\n",
    "        output = format_model_output(epoch, avg_loss, loss, pct_correct, pct_classes)\n",
    "        print(output)\n",
    " \n",
    "        scheduler.step()\n",
    "\n",
    "    torch.save(model.state_dict(), \"PAAI21_CIFAR10_model.pt\")\n",
    "    \n",
    "    return model, pct_correct, pct_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T16:00:37.003917Z",
     "iopub.status.busy": "2021-05-28T16:00:37.003591Z",
     "iopub.status.idle": "2021-05-28T16:42:50.373120Z",
     "shell.execute_reply": "2021-05-28T16:42:50.372086Z",
     "shell.execute_reply.started": "2021-05-28T16:00:37.003887Z"
    }
   },
   "outputs": [],
   "source": [
    "model_base, pct_correct, pct_classes = build_model(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T16:47:12.836264Z",
     "iopub.status.busy": "2021-05-28T16:47:12.835930Z",
     "iopub.status.idle": "2021-05-28T16:47:12.844830Z",
     "shell.execute_reply": "2021-05-28T16:47:12.843651Z",
     "shell.execute_reply.started": "2021-05-28T16:47:12.836234Z"
    },
    "id": "mb3s8M8bshXy",
    "outputId": "1badf520-c596-4c66-9170-6e3a7e7922cc"
   },
   "outputs": [],
   "source": [
    "def plot_results(pct_correct, pct_classes):\n",
    "  ind = [x for x, _ in enumerate(classes)]\n",
    "\n",
    "  fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\n",
    "  fig.suptitle('Accuracy results')\n",
    "\n",
    "  # Bar chart\n",
    "  ax[0].bar(ind, pct_classes, width=0.8, color='#00cc00')\n",
    "  ax[0].bar(ind, pct_classes, width=0.8, color='#00cc00')\n",
    "  ax[0].set_ylabel(\"Percentage\")\n",
    "  ax[0].set_xlabel(\"Classes\")\n",
    "  ax[0].set_xticks(ind)\n",
    "  ax[0].set_xticklabels(classes)\n",
    "  ax[0].set_title(\"Accuracy % per class - resnet18 and CIFAR10\")\n",
    "\n",
    "  # Pie chart\n",
    "  ax[1].pie([100 - pct_correct, pct_correct], labels = ['Error ' + \"{:.2f}\".format(100 - pct_correct) +\n",
    "        '%', 'Accuracy ' + str(pct_correct) + '%'], colors=['red', '#00cc00'], startangle = 90)\n",
    "  ax[1].set_title(\"Accuracy model - resnet18 and CIFAR10\")\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T16:47:16.462876Z",
     "iopub.status.busy": "2021-05-28T16:47:16.462537Z",
     "iopub.status.idle": "2021-05-28T16:47:16.761264Z",
     "shell.execute_reply": "2021-05-28T16:47:16.760441Z",
     "shell.execute_reply.started": "2021-05-28T16:47:16.462847Z"
    }
   },
   "outputs": [],
   "source": [
    "#{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
    "plot_results(pct_correct, pct_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48QW9YtteIR4"
   },
   "source": [
    "# Class activation maps\n",
    "\n",
    "## Terminology\n",
    "- **Receptive field:** The receptive field of a neuron is composed by all\n",
    "  pixels in **X** input that influence it.\n",
    "\n",
    "- **Convolutional units:** A convolutional layer contains units whose receptive\n",
    "  fields cover a patch of the previous layer[1].\n",
    "\n",
    "- **Softmax:** It is a function used to become an output score in a probablity\n",
    "  distribution.\n",
    "\n",
    "- **Global average pooling (GAP):** It is an operation that consists of take the\n",
    "  averag of each feature map and the resulting vector is used to feed the\n",
    "  softmax layer[2]. \n",
    "\n",
    "## Summary\n",
    "\n",
    "1. The convolutional units of several CNNs layers behave as object detectors\n",
    "  even object location is not given. So they have the ability to localize\n",
    "  objects.\n",
    "\n",
    "2. This ability is lost when fully-connected layers are used for classification.\n",
    "\n",
    "3. we can replace fully-connected layers by GAP.\n",
    "\n",
    "4. There is no parameter to optimize in the global average pooling,\n",
    "  thus overfitting is avoided at this layer. So GAP acts as a regularizer.\n",
    "\n",
    "5. We can modify GAP and use it in combination with a class called \n",
    "  **class activation mapping (CAM)** to retain this localization ability\n",
    "  until the final layer.\n",
    "\n",
    "6. Therefore a CNN trained on object categorization is successfully able to\n",
    "  localize the discriminative regions for action classification.\n",
    "\n",
    "7. A **class activation map (CAM)** for a particular category indicates the\n",
    "  discriminative image regions used by the CNN to identify that category.\n",
    "\n",
    "8. we can identify the importance of the image regions by projecting back\n",
    "  the weights of the output layer on to the convolutional feature maps, a\n",
    "  technique we call **class activation mapping**.\n",
    "\n",
    "9. Normally, We perform GAP on the convulitional feature maps and this\n",
    "  output feed a fully-connected layer that produces the final output, So the\n",
    "  weighted sum of GAP output is used to generate the final output\n",
    "  (e.g. category of something).\n",
    " \n",
    "10. We can identify the importance of the image regions by projecting back\n",
    "   the weights of the output layer on to the convolutional feature maps.\n",
    " \n",
    "## CAM description\n",
    "\n",
    "$M_c(x, y) = \\sum_k w_k^c f_k(x,y)$\n",
    "<br><br>\n",
    "Where:<br>\n",
    "$M_c$ is the class activation map for a class $c$<br>\n",
    "$f_k(x,y)$ is the activation of unit $k$ in the last convolutional layer at spatial location $(x,y)$<br>\n",
    "$F^k$ is the output of GAP on $f_k(x,y)$ , then $F^k=\\sum_{x,y} f_k(x,y)$<br>\n",
    "$w_k^c$ indicates the importance of $F^k$ for class $c$\n",
    "\n",
    "\n",
    "## References:\n",
    "[1] https://en.wikipedia.org/wiki/Convolutional_neural_network\n",
    "\n",
    "[2] https://arxiv.org/pdf/1312.4400v3.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T16:47:21.898831Z",
     "iopub.status.busy": "2021-05-28T16:47:21.898483Z",
     "iopub.status.idle": "2021-05-28T16:47:23.753872Z",
     "shell.execute_reply": "2021-05-28T16:47:23.751339Z",
     "shell.execute_reply.started": "2021-05-28T16:47:21.898802Z"
    },
    "id": "7qNBD6Q7ZJ2k",
    "outputId": "abe5d554-01f2-4d89-f724-e347c40bf30b"
   },
   "outputs": [],
   "source": [
    "################################### WARNING!! LOAD EXTERNAL MODEL !!!! ###################################\n",
    "\n",
    "# Load model\n",
    "model_base = Model()\n",
    "model_base.cuda()\n",
    "\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()\n",
    "\n",
    "#### Kaggle ########\n",
    "model_base.load_state_dict(torch.load(\"../input/paaimodel/PAAI21_CIFAR10_model.pt\"))\n",
    "####################\n",
    "\n",
    "model_base.eval()\n",
    "print(\"model loaded!\")\n",
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T16:47:29.502312Z",
     "iopub.status.busy": "2021-05-28T16:47:29.501997Z",
     "iopub.status.idle": "2021-05-28T16:47:29.510074Z",
     "shell.execute_reply": "2021-05-28T16:47:29.509279Z",
     "shell.execute_reply.started": "2021-05-28T16:47:29.502282Z"
    },
    "id": "P3v4Mh0ttXCd"
   },
   "outputs": [],
   "source": [
    "class LayerFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m):\n",
    "        self.hook = m.register_forward_hook(self.hook_fn)\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = ((output.cpu()).data).numpy()\n",
    "\n",
    "    def remove(self): self.hook.remove()\n",
    "\n",
    "\n",
    "def compute_CAM(feature_conv, class_weights):\n",
    "    _, num_channels, h, w = feature_conv.shape\n",
    "    CAM = np.zeros((h, w))\n",
    "    i = 0\n",
    "    for act_map in feature_conv[0]:\n",
    "        CAM += act_map * class_weights[i]\n",
    "        i+=1\n",
    "\n",
    "    # Now we need to normalize our CAM in [0,1] range\n",
    "    CAM = CAM - np.min(CAM)\n",
    "    CAM = CAM / np.max(CAM)\n",
    "\n",
    "    return CAM\n",
    "\n",
    "\n",
    "def get_one_random_sample(test_dataset):\n",
    "    num_total_imgs = len(test_dataset.data)\n",
    "    random_index = random.randint(1, num_total_imgs)\n",
    "    img = test_dataset.data[random_index]\n",
    "    label = test_dataset.targets[random_index]\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuxxJt6OunKU"
   },
   "source": [
    "# Compute CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T16:48:22.915337Z",
     "iopub.status.busy": "2021-05-28T16:48:22.914722Z",
     "iopub.status.idle": "2021-05-28T16:48:22.938919Z",
     "shell.execute_reply": "2021-05-28T16:48:22.938110Z",
     "shell.execute_reply.started": "2021-05-28T16:48:22.915295Z"
    },
    "id": "P1WZj9GGs4m9"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_heatmaps(tensor, model):\n",
    "    #tensor = test_transform(image)\n",
    "    prediction_var = Variable((tensor.unsqueeze(0)).cuda(), requires_grad=True)\n",
    "\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    model._modules.keys()\n",
    "\n",
    "    final_layer = model._modules.get(\"resnet\").layer4[-1]\n",
    "    activated_features = LayerFeatures(final_layer)\n",
    "\n",
    "    prediction = model(prediction_var)\n",
    "    pred_probabilities = F.softmax(prediction, dim=1).data.squeeze()\n",
    "    activated_features.remove()\n",
    "\n",
    "    # Indentify the predicted class\n",
    "    value, index = topk(pred_probabilities, 1)\n",
    "\n",
    "    # Get information from identified class \n",
    "    weight_softmax_params = list(model._modules.get('resnet').fc.parameters())\n",
    "    weight_softmax = np.squeeze(weight_softmax_params[0].cpu().data.numpy())\n",
    "    class_id = topk(pred_probabilities,1)[1].int()\n",
    "    class_weights = weight_softmax[class_id]\n",
    "    cam_img = compute_CAM(activated_features.features, class_weights)\n",
    "\n",
    "    # As we can see, our CAM size does not match with the our\n",
    "    # image. We need to resize our map and interpolate the values\n",
    "    # according to our image\n",
    "    heat_map = skimage.transform.resize(cam_img, tensor.shape[1:3])\n",
    "\n",
    "    return cam_img, heat_map, index, value\n",
    "\n",
    "\n",
    "def crop_preprocess(x, model):\n",
    "    # The 5% of the highest values represent a one of the most\n",
    "    # important values for classification. These values will be\n",
    "    # for experiments modified.\n",
    "    #print(\"myinfo:\", type(x))\n",
    "    cam_img, heat_map, index, value = get_heatmaps(x, model)\n",
    "    percentile = 95\n",
    "    h, w = heat_map.shape\n",
    "    feature_thld = np.percentile(heat_map, percentile)\n",
    "    heat_mask = heat_map.copy()\n",
    "    bk_mask = heat_map.copy()\n",
    "\n",
    "    heat_mask = np.where(heat_mask >= feature_thld, 0.0, 1.0)\n",
    "    bk_mask = np.where(bk_mask >= feature_thld, 1.0, 0.0) # Replace value \n",
    "    x = np.multiply(x, heat_mask)\n",
    "    x = x + bk_mask\n",
    "    #x = x.cpu().numpy()\n",
    "    x = x.to(device='cuda')\n",
    "    #if x.is_cuda == True:\n",
    "    #    print(\"I am in CUDA\")\n",
    "    #else:\n",
    "    #    print(\"I am in CPU\")\n",
    "    #return x\n",
    "    return x.float()\n",
    "\n",
    "def show_sample_images(train_loader):\n",
    "    num_imgs_toshow= 10\n",
    "    data_iter = iter(train_loader)\n",
    "    images, labels = data_iter.next()\n",
    "    # convert images to numpy for display\n",
    "    images = images.cpu().numpy()\n",
    "\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    for i in np.arange(num_imgs_toshow):\n",
    "        ax = fig.add_subplot(2, num_imgs_toshow/2, i + 1, xticks=[], yticks=[])\n",
    "        plt.imshow(np.transpose(images[i], (1, 2, 0)))\n",
    "\n",
    "def vis_demo(original, cam, heat_map, crop):\n",
    "    # Plot\n",
    "    plt.figure()\n",
    "    f, ax = plt.subplots(nrows=1, ncols=4, figsize=(20, 18)) \n",
    "    ax[0].imshow(original)\n",
    "    ax[0].set_title(\"Original\")\n",
    "    ax[1].imshow(cam, alpha=0.5, cmap='jet')\n",
    "    ax[1].set_title(\"Class activation map\")\n",
    "    ax[2].imshow(original)\n",
    "    ax[2].imshow(heat_map, alpha=0.5, cmap='jet')\n",
    "    ax[2].set_title(\"Heat map\")\n",
    "    #ax[3].imshow(crop.argmax())\n",
    "    ax[3].imshow(np.transpose(crop.cpu(), (1, 2, 0)))\n",
    "    ax[3].set_title(\"Cropped image\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T16:48:28.393981Z",
     "iopub.status.busy": "2021-05-28T16:48:28.393656Z",
     "iopub.status.idle": "2021-05-28T16:48:28.937056Z",
     "shell.execute_reply": "2021-05-28T16:48:28.936262Z",
     "shell.execute_reply.started": "2021-05-28T16:48:28.393951Z"
    },
    "id": "bzMk3AupuQsa",
    "outputId": "7e4f17b4-1268-4be0-8643-49336a871662"
   },
   "outputs": [],
   "source": [
    "# CAM\n",
    "image, label =  get_one_random_sample(test_dataset)\n",
    "image_tensor = test_transform(image)\n",
    "cam_img, heat_map, index, value = get_heatmaps(image_tensor, model_base)\n",
    "\n",
    "# CROP most relevant area(s)\n",
    "crop_transformation = transforms.Compose([\n",
    "    #transforms.RandomCrop(32, padding=4),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.Lambda(lambda x: crop_preprocess(x, model_base)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: crop_preprocess(x, model_base)),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "])\n",
    "cropped_image = crop_transformation(image)\n",
    "print(\"IMAGE CLASS: \", classes[label])\n",
    "print(\"PREDICTION: \", classes[index.tolist()[0]])\n",
    "print(\"ACCURACY: {:.2f}%\".format(value.tolist()[0] * 100))\n",
    "vis_demo(image, cam_img, heat_map, cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T16:48:34.395379Z",
     "iopub.status.busy": "2021-05-28T16:48:34.395033Z",
     "iopub.status.idle": "2021-05-28T16:48:36.023723Z",
     "shell.execute_reply": "2021-05-28T16:48:36.022880Z",
     "shell.execute_reply.started": "2021-05-28T16:48:34.395349Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "crop_transformation_a1 = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),#########################\n",
    "    transforms.RandomHorizontalFlip(),##################################\n",
    "    #transforms.Lambda(lambda x: crop_preprocess(x, model_base)),\n",
    "    transforms.ToTensor(),##############################\n",
    "    transforms.Lambda(lambda x: crop_preprocess(x, model_base)),####################\n",
    "])\n",
    "\n",
    "train_full_dataset_a1 = datasets.CIFAR10(\"./data\", train=True,\n",
    "                                 transform=crop_transformation_a1, download=True)\n",
    "\n",
    "test_dataset_a1 = datasets.CIFAR10(\"./data\", train=False,\n",
    "                                transform=test_transform, download=True)\n",
    "\n",
    "# Split datasets\n",
    "train_num_samples_a1 = int(len(train_full_dataset_a1) * 0.9) # 90%(Training set).\n",
    "val_num_samples_a1 = int(len(train_full_dataset_a1) * 0.1)   #10%(Validation set)\n",
    "train_dataset_a1, validation_dataset_a1 = random_split(train_full_dataset_a1, [train_num_samples_a1, val_num_samples_a1])\n",
    "\n",
    "# Loaders\n",
    "train_loader_a1 = torch.utils.data.DataLoader(train_full_dataset_a1,\n",
    "                                           batch_size=128, shuffle=True)\n",
    "test_loader_a1 = torch.utils.data.DataLoader(test_dataset_a1,\n",
    "                                          batch_size=5000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T16:48:37.377806Z",
     "iopub.status.busy": "2021-05-28T16:48:37.377446Z",
     "iopub.status.idle": "2021-05-28T16:48:40.391485Z",
     "shell.execute_reply": "2021-05-28T16:48:40.390714Z",
     "shell.execute_reply.started": "2021-05-28T16:48:37.377774Z"
    }
   },
   "outputs": [],
   "source": [
    "show_sample_images(train_loader_a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-28T08:42:16.944963Z",
     "iopub.status.busy": "2021-05-28T08:42:16.944632Z",
     "iopub.status.idle": "2021-05-28T08:42:30.563308Z",
     "shell.execute_reply": "2021-05-28T08:42:30.561175Z",
     "shell.execute_reply.started": "2021-05-28T08:42:16.944931Z"
    }
   },
   "outputs": [],
   "source": [
    "model_a1, pct_correct_a1, pct_classes_a1 = build_model(train_loader_a1, test_loader_a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T15:29:42.385748Z",
     "iopub.status.busy": "2021-05-25T15:29:42.38536Z",
     "iopub.status.idle": "2021-05-25T15:29:42.717039Z",
     "shell.execute_reply": "2021-05-25T15:29:42.715626Z",
     "shell.execute_reply.started": "2021-05-25T15:29:42.385716Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_results(pct_correct_a1, pct_classes_a1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
